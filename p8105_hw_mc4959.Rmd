---
title: "p8105_homework3"
author: "Meiju Chen"
date: "10/8/2020"
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1

```{r}
data("instacart")
```
This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns.
Observations are the level of items in orders by user. There are user / order variables -- user ID, order ID, order day and order hour. There are also item variables -- name, aisle, department and some numeric codes.


##### How many aisles are there, and which aisles are the most items ordered from?

```{r, echo=FALSE}
instacart %>%
  count(aisle) %>%
  arrange(desc(n))
```

##### Make a plot. Show the number of items ordered in each aisle, limit this to aisles with more than 10000 items ordered.

```{r, echo=FALSE}
instacart %>%
  count(aisle) %>%
  filter(n > 10000) %>%
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>%
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() +
  theme(axis.text = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

##### Make a table. 
Show the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”.

```{r, echo=FALSE}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```


##### Make a table. Show the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week.

```{r, echo=FALSE}
instacart %>% 
	filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
	group_by(product_name, order_dow) %>% 
	summarize(mean_hour = mean(order_hour_of_day)) %>% 
	pivot_wider(
		names_from = order_dow,
		values_from = mean_hour
	)
```



## Problem 2

##### Load, tidy, and otherwise wrangle the data. Include all originally observed variables and values; have useful variable names; include a weekday vs weekend variable; and encode data with reasonable variable classes.

```{r}
accel_df = read_csv(
  "./data/accel_data.csv") %>%
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute",
    names_prefix = "activity_",
    values_to = "activity_count"
    ) %>% 
  mutate(
    activity_count = round(activity_count, digits = 0)
    ) %>% 
  mutate(minute = as.integer(minute),
         activity_count = as.integer(activity_count),
         ) %>% 
  mutate(day_type = case_when(
    day %in% c("Saturday", "Sunday") ~ "Weekend",
    day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday") ~ "Weekday")) %>% 
  mutate(
    day = ordered(
      day, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", 
                                      "Friday","Saturday", "Sunday"))
    ) %>% 
  arrange(week, day)
```

The dataset contains `r nrow(accel_df)` observations and `r ncol(accel_df)` variables. There are several variables for time -- week, day id, day of the week, weekday/weekend, and the minute of the day. Also, there is a variable showing activity of the person in a specific minute. 


##### Total activity over the day.

```{r}
accel_df %>% 
  group_by(week, day) %>% 
  summarize(
    daily_activity = sum(activity_count)
  ) %>% 
  pivot_wider(
    names_from = day,
    values_from = daily_activity
  ) %>% 
  knitr::kable()
```

Throughout the 5 weeks, it seems that the person has steady activity counts during the weekdays, except for Monday in Week 1. The person was more active than usual on the Saturday of Week 1 and Week 2, and less active on the Saturday of Week 4 and Week 5.


##### Make a single-panel plot that shows the 24-hour activity time courses for each day.

```{r}
accel_df %>% 
  group_by(day_id) %>% 
  ggplot(aes(x = minute, y = activity_count, color = day)) +
  geom_point(alpha = 0.5) +
  geom_line()
```

It seems that the person is more active around 10-12am, while less active at other time periods on Sundays in the week. Also, the person is active at Friday and Saturday nights.


## Problem 3

```{r}
data("ny_noaa")
```
This dataset has `r nrow(ny_noaa)` rows and `r ncol(ny_noaa)` columns, containing weather information collected by New York State weather stations. 
The variables include: weather station id, observation date, precipitation, snowfall, snow depth and maximum and minimum of temperature. There are a lot of missing values, especially for the maximum temperatures and minimum temperatures. However, we have a large number of observations available, so this will not be a big issue.


##### Do some data cleaning. Create separate variables for year, month, and day. Ensure observations for temperature, precipitation, and snowfall are given in reasonable units.

```{r}
weather_df = 
  mutate(ny_noaa,
         tmin = as.numeric(tmin),
         tmax = as.numeric(tmax),
         prcp = as.numeric(prcp)) %>% 
  mutate(tmin = tmin / 10,
         tmax = tmax / 10,
         prcp = prcp / 10) %>% 
  separate(date, into = c("year", "month", "day"), sep = "-" ) 
weather_df %>% 
  count(snow) %>%
  mutate(rank = min_rank(n))
```

* "0" is the most observed value. Because there is no snow fall in most days in a year in New York.


##### Make a two-panel plot. Show the average max temperature in January and in July in each station across years.

```{r}
weather_df %>% 
  filter(month %in% c("01", "07")) %>% 
  group_by(id, year, month) %>%
  summarise(mean_tmax = mean(tmax, na.rm = TRUE)) %>% 
  ggplot(aes(x = year, y = mean_tmax, group = id, color = id)) +
  geom_point(alpha = 0.5) + 
  geom_path() +
  facet_grid(. ~ month) +
  theme(
    axis.text = element_text(
      angle = 90, vjust = 0.5, hjust = 1
      ),legend.position = "none")
```

* The maximum temperatures fluctuated in both January and July across the years, and the fluctuation is larger in January. 
* In 1994 and 2004, the max temperatures in January is lower than usual.
* There are outliers in January in 1982, 2004 and 2005, and in July in 1984 and 2004.


##### Make another two-panel plot. (i) show tmax vs tmin; and (ii) s the distribution of snowfall values greater than 0 and less than 100 separately by year.

```{r}
library(p8105.datasets)
library(patchwork)
```


```{r}
tmax_tmin_plot =
weather_df %>% 
  ggplot(aes(x = tmax, y = tmin)) + 
  geom_hex() +
  theme(legend.position = "bottom",
        legend.text = element_text(angle = 60, vjust = 0.5, hjust = 1)) +
  labs(
    title = "Temperature plot",
    x = "Minimum temperature (C)",
    y = "Maxiumum temperature (C)"
  )
```


```{r}
snow_distribution_plot =
weather_df %>% 
  filter(snow > 0, snow < 100) %>% 
  ggplot(aes(x = year, y = snow)) + 
  geom_violin(aes(fill = year), alpha = .5) +
  stat_summary(fun = "median", color = "blue") +
  theme(axis.text = element_text(angle = 90, vjust = 0.5, hjust = 1),
        legend.position = "none")
  labs(
    title = "Snowfall distribution plot",
    x = "snowfall (mm)") 
  
```


```{r, fig.height=20}
tmax_tmin_plot / snow_distribution_plot
```











